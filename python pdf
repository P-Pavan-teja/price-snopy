import io
import boto3
import pdfplumber
import pandas as pd

_s3 = boto3.client("s3")  # IICS Secure Agent IAM creds

def pdf_to_text(file_path, output_path):
    """
    If file_path/output_path are s3:// URIs, 
    read PDF from S3 and write TXT back to S3.
    """
    lines = []
    if str(file_path).startswith("s3://"):
        bucket, key = file_path[5:].split("/", 1)
        obj = _s3.get_object(Bucket=bucket, Key=key)
        pdf_bytes = obj["Body"].read()

        with pdfplumber.open(io.BytesIO(pdf_bytes)) as pdf:
            for page in pdf.pages:
                txt = page.extract_text()
                if txt:
                    lines.append(txt + "\n")

        if output_path and str(output_path).startswith("s3://"):
            b2, k2 = output_path[5:].split("/", 1)
            _s3.put_object(
                Bucket=b2,
                Key=k2,
                Body="".join(lines).encode("utf-8"),
                ContentType="text/plain"
            )
    else:
        # original local fallback
        with pdfplumber.open(file_path) as pdf, open(output_path, "w", encoding="utf-8") as out:
            for page in pdf.pages:
                txt = page.extract_text()
                if txt:
                    out.write(txt + "\n")
    return lines


def read_text_file(file_path):
    """
    If file_path is s3://..., fetch TXT file from S3 into DataFrame.
    """
    if str(file_path).startswith("s3://"):
        bucket, key = file_path[5:].split("/", 1)
        obj = _s3.get_object(Bucket=bucket, Key=key)
        content = obj["Body"].read().decode("utf-8", errors="replace").splitlines()
        return pd.DataFrame({'Line': [line.strip() for line in content]})
    else:
        with open(file_path, "r", encoding="utf-8", errors="replace") as f:
            return pd.DataFrame({'Line': [line.strip() for line in f]})


def write_csv_to_s3(df: pd.DataFrame, s3_uri: str):
    """
    Upload CSV DataFrame directly to S3.
    """
    bucket, key = s3_uri[5:].split("/", 1)
    buf = io.StringIO()
    df.to_csv(buf, index=False)
    _s3.put_object(
        Bucket=bucket,
        Key=key,
        Body=buf.getvalue().encode("utf-8"),
        ContentType="text/csv"
    )
